{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# LangChain Agent with Qiskit Gym MCP Server\n",
    "\n",
    "This notebook demonstrates how to create an AI agent using LangChain that connects to the **qiskit-gym-mcp-server** via the Model Context Protocol (MCP).\n",
    "\n",
    "The agent can interact with qiskit-gym's reinforcement learning environments to:\n",
    "- Create RL environments for quantum circuit synthesis (Permutation, LinearFunction, Clifford)\n",
    "- Train models using PPO or AlphaZero algorithms\n",
    "- Run training in background mode for long sessions\n",
    "- Synthesize optimal circuits using trained models\n",
    "- Manage models (save, load, list, delete)\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "┌─────────────┐     MCP Protocol     ┌──────────────────────────┐\n",
    "│  LangChain  │ ◄──────────────────► │  qiskit-gym-mcp-server   │\n",
    "│    Agent    │                      │                          │\n",
    "└─────────────┘                      │  ┌────────────────────┐  │\n",
    "                                     │  │    qiskit-gym      │  │\n",
    "                                     │  │  (RL Environments) │  │\n",
    "                                     │  └────────────────────┘  │\n",
    "                                     └──────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### 1. Install Dependencies\n",
    "\n",
    "Run these commands in your terminal:\n",
    "\n",
    "```bash\n",
    "# Install the MCP server\n",
    "pip install qiskit-gym-mcp-server\n",
    "\n",
    "# Install LangChain dependencies\n",
    "pip install langchain langchain-mcp-adapters python-dotenv\n",
    "\n",
    "# Install your preferred LLM provider (choose one):\n",
    "pip install langchain-openai       # For OpenAI\n",
    "pip install langchain-anthropic    # For Anthropic Claude\n",
    "pip install langchain-google-genai # For Google Gemini\n",
    "pip install langchain-ollama       # For local Ollama\n",
    "pip install langchain-ibm          # For IBM Watsonx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "### 2. Configure Environment Variables\n",
    "\n",
    "Set your LLM provider API key.\n",
    "\n",
    "You can either:\n",
    "- Set them in a `.env` file in this directory\n",
    "- Set them as environment variables\n",
    "- Enter them in the cell below\n",
    "\n",
    "**Note:** This server doesn't require IBM Quantum credentials - it uses local qiskit-gym for RL training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.agents import create_agent\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Load from .env file if it exists\n",
    "load_dotenv()\n",
    "\n",
    "# Set your LLM provider API key (uncomment the one you're using):\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-api-key\"\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# Verify configuration\n",
    "print(\"Configuration status:\")\n",
    "print(f\"  OPENAI_API_KEY: {'✓ Set' if os.getenv('OPENAI_API_KEY') else '✗ Not set'}\")\n",
    "print(f\"  ANTHROPIC_API_KEY: {'✓ Set' if os.getenv('ANTHROPIC_API_KEY') else '✗ Not set'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Choose Your LLM Provider\n",
    "\n",
    "Run **one** of the following cells based on your preferred LLM provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "print(\"Using OpenAI GPT-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Anthropic Claude\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "llm = ChatAnthropic(model=\"claude-sonnet-4-20250514\", temperature=0)\n",
    "print(\"Using Anthropic Claude Sonnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Google Gemini\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0)\n",
    "print(\"Using Google Gemini Pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 4: Local Ollama (no API key needed)\n",
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "print(\"Using local Ollama with Llama 3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 5: IBM Watsonx\n",
    "from langchain_ibm import ChatWatsonx\n",
    "llm = ChatWatsonx(\n",
    "    model_id=\"ibm/granite-3-8b-instruct\",\n",
    "    url=os.getenv(\"WATSONX_URL\", \"https://us-south.ml.cloud.ibm.com\"),\n",
    "    project_id=os.getenv(\"WATSONX_PROJECT_ID\"),\n",
    "    params={\"temperature\": 0, \"max_tokens\": 4096},\n",
    ")\n",
    "print(\"Using IBM Watsonx Granite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Define the System Prompt\n",
    "\n",
    "This prompt tells the agent what it can do and how to behave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "SYSTEM_PROMPT = \"\"\"You are a helpful quantum computing assistant with access to qiskit-gym's\nreinforcement learning-based circuit synthesis through the MCP server.\n\nYou can help users train RL models and synthesize optimal quantum circuits.\n\n## IMPORTANT: Three Problem Types (Choose Correctly!)\n\nThere are THREE distinct environment types. Pay attention to what the user asks for:\n\n1. **Permutation** (create_permutation_env_tool):\n   - For QUBIT ROUTING / SWAP gate synthesis\n   - Input: A permutation like [2, 0, 1, 3] meaning qubit 0→2, 1→0, 2→1, 3→3\n   - Output: Optimal SWAP circuit to achieve that permutation\n   - Keywords: \"permutation\", \"swap\", \"routing\", \"qubit mapping\"\n\n2. **LinearFunction** (create_linear_function_env_tool):\n   - For CNOT circuit synthesis of LINEAR BOOLEAN FUNCTIONS\n   - Input: An invertible binary matrix representing the linear function\n   - Output: Optimal CNOT-only circuit\n   - Keywords: \"linear function\", \"CNOT\", \"cx\", \"linear reversible\", \"parity network\"\n\n3. **Clifford** (create_clifford_env_tool):\n   - For CLIFFORD CIRCUIT synthesis (H, S, CNOT gates)\n   - Input: A Clifford tableau\n   - Output: Optimal Clifford circuit\n   - Keywords: \"clifford\", \"stabilizer\", \"H+S+CNOT\"\n\n**When the user says \"linear\", determine if they mean:**\n- \"linear topology\" → refers to the COUPLING MAP shape (a line: 0-1-2-3)\n- \"linear function\" → refers to the LinearFunction ENVIRONMENT TYPE\n\n## Environment Creation\n- create_permutation_env_tool: Create PermutationGym for SWAP routing\n- create_linear_function_env_tool: Create LinearFunctionGym for CNOT synthesis\n- create_clifford_env_tool: Create CliffordGym for Clifford circuit synthesis\n- list_environments_tool: List active environments\n- delete_environment_tool: Remove an environment\n\n## Training\n- start_training_tool: Start RL training (supports background=True for async training)\n- batch_train_environments_tool: Train multiple environments (supports background=True)\n- get_training_status_tool: Check training progress\n- wait_for_training_tool: Wait for background training to complete\n- stop_training_tool: Stop a running training session\n- list_training_sessions_tool: List all training sessions\n\n## Synthesis\n- synthesize_permutation_tool: Generate optimal SWAP circuit for a permutation\n- synthesize_linear_function_tool: Generate optimal CNOT circuit\n- synthesize_clifford_tool: Generate optimal Clifford circuit\n\n## Model Management\n- save_model_tool: Save trained model to disk\n- load_model_tool: Load model from disk\n- list_saved_models_tool: List models on disk\n- list_loaded_models_tool: List models in memory\n\n## Utility Tools\n- generate_random_permutation_tool: Generate random permutation for testing\n- generate_random_linear_function_tool: Generate random linear function\n- generate_random_clifford_tool: Generate random Clifford element\n\n## Hardware Presets\nAvailable presets for coupling maps:\n- linear_5, linear_10: Linear chain topologies\n- grid_3x3, grid_5x5: Grid topologies\n- ibm_heron_r1, ibm_heron_r2: IBM Heron heavy-hex topology\n- ibm_nighthawk: IBM Nighthawk 10x12 grid\n\n## RL Algorithms\n- ppo: Proximal Policy Optimization (recommended, fast)\n- alphazero: MCTS with neural networks (better for complex problems, slower)\n\n## Policy Networks\n- basic: Simple feedforward network (good for <8 qubits)\n- conv1d: 1D convolutional network (better for larger problems)\n\n## IMPORTANT: Background Training\n**ALWAYS use background=True for training** to avoid connection timeouts:\n- start_training_tool(..., background=True) - returns immediately with session_id\n- batch_train_environments_tool(..., background=True) - returns immediately with session_ids\n- Use get_training_status_tool(session_id) to check progress\n- Use wait_for_training_tool(session_id) to block until complete\n\nOnly use synchronous training (background=False) for very short demos (< 10 iterations).\n\n## Workflow Tips\n1. **Always use background=True** for any real training\n2. For batch training multiple environments, use batch_train_environments_tool with background=True\n3. Poll progress with get_training_status_tool or wait with wait_for_training_tool\n4. Save models you want to keep with save_model_tool\n5. Use list_training_sessions_tool to see all running/completed training\n\nWhen a user asks to train a model:\n1. Create an appropriate environment using create_*_env_tool\n2. Start training with start_training_tool(..., background=True)\n3. Use get_training_status_tool to check progress periodically\n4. When complete, save the model if needed with save_model_tool\n\"\"\""
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Connect to the MCP Server and Create Agent\n",
    "\n",
    "Now let's connect to the qiskit-gym MCP server and create our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure MCP client for qiskit-gym server\n",
    "mcp_client = MultiServerMCPClient({\n",
    "    \"qiskit-gym\": {\n",
    "        \"transport\": \"stdio\",\n",
    "        \"command\": \"qiskit-gym-mcp-server\",\n",
    "        \"args\": [],\n",
    "        \"env\": {},\n",
    "    }\n",
    "})\n",
    "\n",
    "print(\"MCP client configured for qiskit-gym-mcp-server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "# Helper function to run queries with optional conversation history\nasync def run_agent_query(agent, query: str, history: list = None) -> tuple[str, list]:\n    \"\"\"Run a query through the agent with conversation history.\n    \n    Args:\n        agent: The LangChain agent\n        query: The user's question or request\n        history: Optional list of previous messages for context\n        \n    Returns:\n        Tuple of (response_text, updated_history)\n    \"\"\"\n    messages = list(history) if history else []\n    messages.append(HumanMessage(content=query))\n    \n    result = await agent.ainvoke({\"messages\": messages})\n    result_messages = result.get(\"messages\", [])\n    \n    if result_messages:\n        response = result_messages[-1].content\n        return response, result_messages\n    \n    return \"No response generated.\", messages"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Example 1: Basic Training Workflow\n",
    "\n",
    "Let's create an environment and train a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "async with mcp_client.session(\"qiskit-gym\") as session:\n    # Load tools and create agent\n    tools = await load_mcp_tools(session)\n    print(f\"Loaded {len(tools)} tools from MCP server\")\n    \n    agent = create_agent(llm, tools, system_prompt=SYSTEM_PROMPT)\n    \n    # Run a training query (using background=True as recommended)\n    query = \"\"\"Create a permutation environment for a 5-qubit linear chain\n    and train a model with PPO for 20 iterations using background=True.\n    Then wait for training to complete and show the results.\"\"\"\n    \n    print(f\"Query: {query}\\n\")\n    print(\"-\" * 50)\n    response, _ = await run_agent_query(agent, query)\n    print(response)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Example 2: Background Training\n",
    "\n",
    "For longer training sessions, use background mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": "async with mcp_client.session(\"qiskit-gym\") as session:\n    tools = await load_mcp_tools(session)\n    agent = create_agent(llm, tools, system_prompt=SYSTEM_PROMPT)\n    \n    # Start background training\n    query = \"\"\"Create a Clifford environment for a 4-qubit grid (2x2)\n    and start training in the background with PPO for 50 iterations.\n    Then check the training status.\"\"\"\n    \n    print(f\"Query: {query}\\n\")\n    print(\"-\" * 50)\n    response, _ = await run_agent_query(agent, query)\n    print(response)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Example 3: Wait for Training and Synthesize\n",
    "\n",
    "Wait for background training to complete, then use the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "async with mcp_client.session(\"qiskit-gym\") as session:\n    tools = await load_mcp_tools(session)\n    agent = create_agent(llm, tools, system_prompt=SYSTEM_PROMPT)\n    \n    # Complete workflow: environment -> train (background) -> wait -> synthesize\n    query = \"\"\"Help me with this workflow:\n    1. Create a permutation environment for a 4-qubit linear chain\n    2. Train a model with PPO for 30 iterations (use background=True)\n    3. Wait for training to complete\n    4. Generate a random permutation for testing\n    5. Use the trained model to synthesize an optimal circuit\n    \"\"\"\n    \n    print(f\"Query: {query}\\n\")\n    print(\"-\" * 50)\n    response, _ = await run_agent_query(agent, query)\n    print(response)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Example 4: List Resources\n",
    "\n",
    "Check what environments and models are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "async with mcp_client.session(\"qiskit-gym\") as session:\n    tools = await load_mcp_tools(session)\n    agent = create_agent(llm, tools, system_prompt=SYSTEM_PROMPT)\n    \n    query = \"List all active environments, training sessions, and loaded models.\"\n    \n    print(f\"Query: {query}\\n\")\n    print(\"-\" * 50)\n    response, _ = await run_agent_query(agent, query)\n    print(response)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Example 5: Custom Query\n",
    "\n",
    "Try your own query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": "# Edit this query to try your own requests\nmy_query = \"What hardware presets are available for creating environments?\"\n\nasync with mcp_client.session(\"qiskit-gym\") as session:\n    tools = await load_mcp_tools(session)\n    agent = create_agent(llm, tools, system_prompt=SYSTEM_PROMPT)\n    \n    print(f\"Query: {my_query}\\n\")\n    print(\"-\" * 50)\n    response, _ = await run_agent_query(agent, my_query)\n    print(response)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": "## Available Tools Reference\n\nHere's a quick reference of all available tools:\n\n### Environment Management\n| Tool | Description |\n|------|-------------|\n| `create_permutation_env_tool` | Create PermutationGym for SWAP routing |\n| `create_linear_function_env_tool` | Create LinearFunctionGym for CNOT synthesis |\n| `create_clifford_env_tool` | Create CliffordGym with custom gate sets |\n| `list_environments_tool` | List active environments |\n| `delete_environment_tool` | Remove an environment |\n\n### Training\n| Tool | Description |\n|------|-------------|\n| `start_training_tool` | Start RL training (supports `background=True`) |\n| `batch_train_environments_tool` | Train multiple environments (supports `background=True`) |\n| `wait_for_training_tool` | Wait for background training to complete |\n| `get_training_status_tool` | Get training progress and metrics |\n| `stop_training_tool` | Stop a training session |\n| `list_training_sessions_tool` | List all training sessions |\n\n### Synthesis\n| Tool | Description |\n|------|-------------|\n| `synthesize_permutation_tool` | Generate optimal SWAP circuit |\n| `synthesize_linear_function_tool` | Generate optimal CNOT circuit |\n| `synthesize_clifford_tool` | Generate optimal Clifford circuit |\n\n### Model Management\n| Tool | Description |\n|------|-------------|\n| `save_model_tool` | Save trained model to disk |\n| `load_model_tool` | Load model from disk |\n| `list_saved_models_tool` | List models on disk |\n| `list_loaded_models_tool` | List models in memory |\n\n### Important: Use Background Training!\n**Always use `background=True`** for training to avoid connection timeouts:\n```python\n# Good - returns immediately\nstart_training_tool(env_id, num_iterations=100, background=True)\nbatch_train_environments_tool(env_ids, num_iterations=100, background=True)\n\n# Then check progress or wait\nget_training_status_tool(session_id)\nwait_for_training_tool(session_id, timeout=600)\n```"
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Hardware Presets\n",
    "\n",
    "| Preset | Qubits | Topology | Description |\n",
    "|--------|--------|----------|-------------|\n",
    "| `linear_5` | 5 | Line | 5-qubit linear chain |\n",
    "| `linear_10` | 10 | Line | 10-qubit linear chain |\n",
    "| `grid_3x3` | 9 | Grid | 3x3 square grid |\n",
    "| `grid_5x5` | 25 | Grid | 5x5 square grid |\n",
    "| `ibm_heron_r1` | 133 | Heavy-hex | IBM Heron r1 processor |\n",
    "| `ibm_heron_r2` | 156 | Heavy-hex | IBM Heron r2 processor |\n",
    "| `ibm_nighthawk` | 120 | 10x12 grid | IBM Nighthawk |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}