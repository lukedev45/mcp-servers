{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Agent with Qiskit IBM Runtime MCP Server\n",
    "\n",
    "This notebook demonstrates how to create an AI agent using LangGraph that connects to the **qiskit-ibm-runtime-mcp-server** via the Model Context Protocol (MCP).\n",
    "\n",
    "The agent can interact with IBM Quantum services to:\n",
    "- List available quantum backends\n",
    "- Find the least busy backend\n",
    "- Get detailed backend properties and calibration data\n",
    "- Manage quantum jobs\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "┌─────────────┐     MCP Protocol     ┌──────────────────────────────────┐\n",
    "│  LangChain  │ ◄──────────────────► │ qiskit-ibm-runtime-mcp-server    │\n",
    "│    Agent    │                      │                                  │\n",
    "└─────────────┘                      │  ┌────────────────────────────┐  │\n",
    "                                     │  │   qiskit-ibm-runtime       │  │\n",
    "                                     │  └────────────────────────────┘  │\n",
    "                                     │               │                  │\n",
    "                                     └───────────────│──────────────────┘\n",
    "                                                     ▼\n",
    "                                            ┌─────────────────┐\n",
    "                                            │  IBM Quantum    │\n",
    "                                            │    Cloud        │\n",
    "                                            └─────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### 1. Install Dependencies\n",
    "\n",
    "Run these commands in your terminal:\n",
    "\n",
    "```bash\n",
    "# Install the MCP server\n",
    "pip install qiskit-ibm-runtime-mcp-server\n",
    "\n",
    "# Install LangChain dependencies\n",
    "pip install langgraph langchain-mcp-adapters python-dotenv\n",
    "\n",
    "# Install your preferred LLM provider (choose one):\n",
    "pip install langchain-openai       # For OpenAI\n",
    "pip install langchain-anthropic    # For Anthropic Claude\n",
    "pip install langchain-google-genai # For Google Gemini\n",
    "pip install langchain-ollama       # For local Ollama\n",
    "pip install langchain-ibm          # For IBM Watsonx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configure Environment Variables\n",
    "\n",
    "Set your IBM Quantum token and (optionally) instance for faster startup.\n",
    "\n",
    "You can either:\n",
    "- Set them in a `.env` file in this directory\n",
    "- Set them as environment variables\n",
    "- Enter them in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load from .env file if it exists\n",
    "load_dotenv()\n",
    "\n",
    "# Or set directly (uncomment and fill in):\n",
    "# os.environ[\"QISKIT_IBM_TOKEN\"] = \"your-ibm-quantum-token\"\n",
    "# os.environ[\"QISKIT_IBM_RUNTIME_MCP_INSTANCE\"] = \"your-instance-name\"  # Optional but recommended for faster startup\n",
    "\n",
    "# Set your LLM provider API key (uncomment the one you're using):\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-api-key\"\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# Verify configuration\n",
    "print(\"Configuration status:\")\n",
    "print(f\"  QISKIT_IBM_TOKEN: {'✓ Set' if os.getenv('QISKIT_IBM_TOKEN') else '✗ Not set'}\")\n",
    "print(f\"  QISKIT_IBM_RUNTIME_MCP_INSTANCE: {'✓ Set (' + os.getenv('QISKIT_IBM_RUNTIME_MCP_INSTANCE') + ')' if os.getenv('QISKIT_IBM_RUNTIME_MCP_INSTANCE') else '✗ Not set (slower startup)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find Your IBM Quantum Instance (Optional but Recommended)\n",
    "\n",
    "Setting `QISKIT_IBM_RUNTIME_MCP_INSTANCE` significantly speeds up startup (from ~30 seconds to ~2 seconds).\n",
    "\n",
    "Run this cell to find your available instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to find your available instances\n",
    "# from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "# service = QiskitRuntimeService()\n",
    "# print(\"Available instances:\")\n",
    "# for instance in service.instances():\n",
    "#     print(f\"  - {instance['name']} ({instance['plan']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "\n",
    "# Suppress deprecation warning for create_react_agent\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Your LLM Provider\n",
    "\n",
    "Run **one** of the following cells based on your preferred LLM provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "print(\"Using OpenAI GPT-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Anthropic Claude\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "llm = ChatAnthropic(model=\"claude-sonnet-4-20250514\", temperature=0)\n",
    "print(\"Using Anthropic Claude Sonnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Google Gemini\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0)\n",
    "print(\"Using Google Gemini Pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 4: Local Ollama (no API key needed)\n",
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "print(\"Using local Ollama with Llama 3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 5: IBM Watsonx\n",
    "from langchain_ibm import ChatWatsonx\n",
    "llm = ChatWatsonx(\n",
    "    model_id=\"ibm/granite-3-8b-instruct\",\n",
    "    url=os.getenv(\"WATSONX_URL\", \"https://us-south.ml.cloud.ibm.com\"),\n",
    "    project_id=os.getenv(\"WATSONX_PROJECT_ID\"),\n",
    "    params={\"temperature\": 0, \"max_tokens\": 4096},\n",
    ")\n",
    "print(\"Using IBM Watsonx Granite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the System Prompt\n",
    "\n",
    "This prompt tells the agent what it can do and how to behave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a helpful quantum computing assistant with access to IBM Quantum services\n",
    "through the Qiskit IBM Runtime MCP server.\n",
    "\n",
    "You can help users:\n",
    "- Set up their IBM Quantum account (setup_ibm_quantum_account_tool)\n",
    "- List available quantum backends (list_backends_tool)\n",
    "- Find the least busy backend for running jobs (least_busy_backend_tool)\n",
    "- Get detailed backend properties (get_backend_properties_tool)\n",
    "- Get backend calibration data including T1, T2, error rates, and faulty qubits (get_backend_calibration_tool)\n",
    "- List recent jobs (list_my_jobs_tool)\n",
    "- Check job status (get_job_status_tool)\n",
    "- Cancel jobs (cancel_job_tool)\n",
    "\n",
    "Always provide clear explanations about quantum computing concepts when relevant.\n",
    "When listing backends, highlight key properties like qubit count and operational status.\n",
    "When showing calibration data, highlight faulty qubits/gates that users should avoid.\n",
    "If an operation fails, explain the error and suggest possible solutions.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the MCP Client\n",
    "\n",
    "This configures the connection to the qiskit-ibm-runtime-mcp-server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mcp_client():\n",
    "    \"\"\"Create and return an MCP client configured for the Qiskit IBM Runtime server.\"\"\"\n",
    "    return MultiServerMCPClient(\n",
    "        {\n",
    "            \"qiskit-ibm-runtime\": {\n",
    "                \"transport\": \"stdio\",\n",
    "                \"command\": \"qiskit-ibm-runtime-mcp-server\",\n",
    "                \"args\": [],\n",
    "                \"env\": {\n",
    "                    \"QISKIT_IBM_TOKEN\": os.getenv(\"QISKIT_IBM_TOKEN\", \"\"),\n",
    "                    \"QISKIT_IBM_RUNTIME_MCP_INSTANCE\": os.getenv(\"QISKIT_IBM_RUNTIME_MCP_INSTANCE\", \"\"),\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Agent\n",
    "\n",
    "Now we'll create a function that sets up the agent with a persistent MCP session.\n",
    "\n",
    "Using a persistent session is important because it:\n",
    "- Keeps a single MCP server process running\n",
    "- Reuses the IBM Quantum service connection\n",
    "- Makes tool calls much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_agent_with_session(session):\n",
    "    \"\"\"Create a LangGraph agent using an existing MCP session.\"\"\"\n",
    "    # Load tools from the existing session\n",
    "    tools = await load_mcp_tools(session)\n",
    "    print(f\"Loaded {len(tools)} tools from MCP server:\")\n",
    "    for tool in tools:\n",
    "        print(f\"  - {tool.name}\")\n",
    "    \n",
    "    # Create the ReAct agent\n",
    "    agent = create_react_agent(llm, tools, prompt=SYSTEM_PROMPT)\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function to Run Queries\n",
    "\n",
    "This function sends a query to the agent and returns the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "async def ask_agent(agent, query: str) -> str:\n",
    "    \"\"\"Send a query to the agent and return the response.\"\"\"\n",
    "    result = await agent.ainvoke({\"messages\": [HumanMessage(content=query)]})\n",
    "    messages = result.get(\"messages\", [])\n",
    "    if messages:\n",
    "        return messages[-1].content\n",
    "    return \"No response generated.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Agent\n",
    "\n",
    "Now let's create the agent and ask it some questions!\n",
    "\n",
    "The following cell starts the MCP server, creates the agent, and keeps the session open for multiple queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MCP client and start a persistent session\n",
    "mcp_client = get_mcp_client()\n",
    "\n",
    "print(\"Starting MCP server and creating agent...\")\n",
    "print(\"(This may take a few seconds on first run)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: List Available Backends\n",
    "\n",
    "Let's ask the agent to show us what quantum backends are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with mcp_client.session(\"qiskit-ibm-runtime\") as session:\n",
    "    agent = await create_agent_with_session(session)\n",
    "    \n",
    "    response = await ask_agent(agent, \"What quantum backends are available?\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Find the Least Busy Backend\n",
    "\n",
    "When you want to run a job quickly, you want the backend with the shortest queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with mcp_client.session(\"qiskit-ibm-runtime\") as session:\n",
    "    agent = await create_agent_with_session(session)\n",
    "    \n",
    "    response = await ask_agent(agent, \"Which backend has the shortest queue right now?\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Get Backend Details\n",
    "\n",
    "Let's get detailed information about a specific backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with mcp_client.session(\"qiskit-ibm-runtime\") as session:\n",
    "    agent = await create_agent_with_session(session)\n",
    "    \n",
    "    response = await ask_agent(agent, \"Tell me about the ibm_boston backend, including its calibration data\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Check Recent Jobs\n",
    "\n",
    "See what quantum jobs you've submitted recently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with mcp_client.session(\"qiskit-ibm-runtime\") as session:\n",
    "    agent = await create_agent_with_session(session)\n",
    "    \n",
    "    response = await ask_agent(agent, \"Show me my recent quantum jobs\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Interactive Chat\n",
    "\n",
    "Run this cell to have an interactive conversation with the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with mcp_client.session(\"qiskit-ibm-runtime\") as session:\n",
    "    agent = await create_agent_with_session(session)\n",
    "    print(\"Agent ready! Type your questions below.\")\n",
    "    print(\"Enter 'quit' to stop.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"You: \").strip()\n",
    "            if not query:\n",
    "                continue\n",
    "            if query.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            response = await ask_agent(agent, query)\n",
    "            print(f\"\\nAssistant: {response}\\n\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Queries\n",
    "\n",
    "Use this cell to ask the agent any question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your question here:\n",
    "MY_QUESTION = \"Compare the ibm_boston and ibm_sherbrooke backends\"\n",
    "\n",
    "async with mcp_client.session(\"qiskit-ibm-runtime\") as session:\n",
    "    agent = await create_agent_with_session(session)\n",
    "    response = await ask_agent(agent, MY_QUESTION)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Tools\n",
    "\n",
    "The agent has access to these tools provided by the MCP server:\n",
    "\n",
    "| Tool | Description |\n",
    "|------|-------------|\n",
    "| `setup_ibm_quantum_account_tool` | Set up IBM Quantum account with credentials |\n",
    "| `list_backends_tool` | List all available quantum backends |\n",
    "| `least_busy_backend_tool` | Find the least busy operational backend |\n",
    "| `get_backend_properties_tool` | Get detailed properties of a specific backend |\n",
    "| `get_backend_calibration_tool` | Get calibration data (T1, T2, error rates, faulty qubits) |\n",
    "| `list_my_jobs_tool` | List user's recent quantum jobs |\n",
    "| `get_job_status_tool` | Get status of a specific job |\n",
    "| `cancel_job_tool` | Cancel a running or queued job |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Slow startup?\n",
    "Set `QISKIT_IBM_RUNTIME_MCP_INSTANCE` environment variable to skip instance lookup.\n",
    "\n",
    "### Authentication errors?\n",
    "Verify your `QISKIT_IBM_TOKEN` is correct and your IBM Quantum account is active.\n",
    "\n",
    "### MCP server not found?\n",
    "Make sure `qiskit-ibm-runtime-mcp-server` is installed: `pip install qiskit-ibm-runtime-mcp-server`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
